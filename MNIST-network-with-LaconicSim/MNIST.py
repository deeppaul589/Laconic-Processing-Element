#import tempfile
#import os
import numpy as np
from matplotlib import pyplot as plt
#import tensorflow as tf
import skimage.measure
from tensorflow import keras
from laconicSim import *



mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Load MNIST dataset
mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

train_images = train_images.astype(np.int32)
test_images = test_images.astype(np.int32)

print(len(train_images))

#print(train_images[0])

train_images = train_images - 128
test_images = test_images - 128

train_images = train_images.astype(np.int8)
test_images = test_images.astype(np.int8)

#print(train_images[6])

w1_conv = np.array([[-11,68,-8],
                   [53, 127, -49],
                   [-31, -30, 33]])

w_fc = np.array([[-22, 4, 1, -30, -22, -9, -64, -35, -62, -102, -66, -17, -6, 7, -39, -9, -5, 5, -6, -4, 6, -2, -20, -5, -16, 7, -22, -30, -23, -7, -9, -7, 3, 4, 16, 0, -1, -23, -61, -48, -21, -6, -16, -4, 2, 9, 12, 27, 16, 3, 8, -74, -46, -40, -6, -8, 1, -10, 9, 0, 15, 9, -1, 19, -47, -43, -20, 0, -8, -14, -1, -9, -28, -17, -1, 4, 11, -32, 1, -36, 4, 10, 14, -1, -22, -58, -15, 0, 0, 5, 19, -39, 6, 7, 14, 14, 3, -45, -41, -11, -2, 8, 5, -7, -27, 1, 12, 8, 13, 0, -48, -15, 3, -6, 3, 1, -7, -13, -5, 7, 6, 12, 8, -14, 1, -4, -6, 5, -7, -41, -30, -10, 5, 7, 5, 21, 6, 2, -5, -13, 4, -20, -15, -28, -35, -18, 4, 11, 13, 14, 4, -8, -30, -23, -29, -22, -5, -33, -49, -36, -44, -42, -46, -48, -32, -61, -38, -22, 2], [-15, 9, 3, -18, -26, -19, 2, 11, -29, -20, -22, -23, -27, -19, -17, -9, -18, -10, -8, 15, 21, -5, -1, 3, -11, -27, -23, -10, 11, -18, -16, -18, -7, -13, -15, -13, -1, -2, -53, -48, -13, -31, -29, -29, -10, -8, -18, -11, 5, -5, -18, -61, -5, -29, -29, -11, -16, -11, 18, 17, -1, -19, -26, -57, -67, -4, -21, -17, -28, -13, -19, 33, 27, -16, -20, -36, -32, -14, -30, 7, -48, 18, -22, -18, 24, 14, -3, -23, -39, -37, -18, 2, -38, -31, -5, -30, 6, 31, 6, -38, -70, -18, -45, -44, -5, -51, -69, -21, -2, -1, 30, -9, -35, -19, -2, -17, -31, -43, -49, -30, -9, -4, 2, 15, -9, -6, 6, 5, 1, 2, -33, 20, 11, 7, 0, -11, -11, -7, 15, 16, 3, -11, 19, -22, -24, 14, 4, 8, -6, 1, 4, 10, 4, -13, -23, 13, -21, -33, -21, -16, -44, -45, -34, -35, -66, -13, -29, -10, -27], [11, -17, -4, 6, -4, 6, 8, 8, -10, -24, -32, -13, -13, -24, -10, -3, 4, 21, 1, 14, 12, 1, -10, -20, -47, 22, -7, -1, 4, 12, 8, -1, 6, 16, 14, -4, -5, -33, -53, 0, 7, 0, 8, 2, 2, 2, 4, 0, 11, 2, -19, -47, 5, 5, 11, -13, -2, -12, 0, 0, 7, -1, -12, -1, -61, -35, -17, -19, -31, -40, -37, -36, -23, -21, -5, -7, -24, 23, -22, -44, -51, -32, -11, -17, -8, -14, -9, -1, -15, -7, 43, -4, 4, 2, -4, -8, 12, 21, -5, -8, 2, -3, -1, 28, -10, 24, 12, 3, 10, 19, 14, 4, 7, -9, 7, 19, 52, -6, -1, 9, 10, 5, 4, 3, 6, 3, 0, 14, 22, 26, 2, 4, 12, 8, 7, 1, -10, -9, 8, 15, 12, 8, 22, -26, -3, -5, -5, -2, -3, -8, -14, -4, 4, 5, -3, 14, -20, -43, -59, -43, -72, -50, -18, -14, -15, -35, -23, -43, 25], [-11, 12, 12, -38, -44, -28, 3, -60, -26, -79, -14, -21, -8, -3, 14, -3, 9, 13, 2, 9, 9, -3, -9, -28, -44, -22, 21, 20, 12, 11, 4, 4, 3, 10, 8, -8, -7, -27, -78, -15, 2, 8, 3, 5, 4, 5, 6, 5, 12, -2, -11, -92, -18, 15, 10, -8, -12, -26, 0, 6, 10, 8, 7, -6, -98, 0, -10, -19, -34, -32, -13, 13, 8, 2, 3, -20, -32, -33, -51, -30, -27, -20, -2, -9, 13, -1, 1, 3, -22, -33, -54, 20, 9, -10, -19, -22, 7, 11, -13, -8, 4, 6, 0, -50, 16, 28, 8, -9, -27, -21, -18, -7, 10, -2, 10, 5, -79, 15, 9, 11, 3, -6, -25, -12, 5, 13, -2, 10, 3, -75, 5, 6, 9, 5, -3, -9, -4, -1, 9, 5, -2, -31, -53, 39, 17, 12, 8, 4, 5, 6, 3, -3, 0, -18, -26, -14, 21, 3, 18, 29, 24, 12, 14, 7, 8, 2, -15, -32, 5], [-21, -16, -36, -32, -34, -82, -58, -56, -61, -42, -33, -33, -4, -17, -6, -9, -24, -34, -45, -31, -18, -14, 3, 7, 5, -37, -12, 11, 5, 2, -10, -17, -14, -10, -6, -8, -5, 26, -8, -21, 3, 6, 3, -6, -13, -24, -28, -13, -3, -1, 8, -4, -38, -21, -3, -12, -8, -5, -17, -23, 2, -6, -16, -22, -21, -40, -30, -9, 5, 9, 28, -11, 12, 4, -5, -8, -29, -48, -28, -5, 13, 19, 28, 26, -13, 11, 17, 24, 14, -9, -4, -31, 14, 8, 20, 7, 14, 3, 17, 11, 11, 10, -18, -36, -22, -30, -12, 6, 3, -1, 8, 19, 0, -15, -13, -9, -46, 3, -18, -10, -22, -24, -24, 0, 3, -12, -28, -17, -48, -44, -40, -26, -30, -28, -24, -8, -9, -5, -4, -1, -10, -12, -36, -13, -71, -37, -6, -7, -6, -6, -4, 4, 5, 7, -20, -2, -3, -14, -37, -10, -13, -14, -13, -14, -11, -25, -22, -12, 8], [-19, 10, -8, -29, -35, -52, -102, -46, -6, -22, -33, -11, -12, 6, -18, -18, -25, -14, -12, -13, -4, -7, -11, 0, -8, 18, 4, -46, -27, -4, -3, -10, -6, 1, 9, -4, 1, 5, 21, -23, -55, -7, -4, 7, 4, -8, -10, 1, 15, 7, 28, 34, -47, -37, -13, 1, 9, 6, 2, -25, -16, -15, -6, 34, 67, -53, -17, 13, 2, 4, 19, 23, -11, -24, -25, -60, -22, 54, -37, -5, -4, 2, 22, 16, 4, -19, -16, 2, -12, -48, -16, -23, -5, -15, -14, -1, 10, -7, -23, -15, -4, 2, -2, -51, -31, -3, 14, -13, -18, -16, -20, -5, 7, -6, 1, 5, -43, -13, 0, 13, 9, -1, -6, -6, 2, 4, -3, 5, 4, -34, -8, 2, -3, 5, 3, 5, 2, 1, 9, 5, 14, -3, -18, -13, 12, 0, 2, 6, 5, 5, 5, 0, 2, 0, 1, 9, 5, 13, -14, -4, 3, 4, 3, 10, 7, -11, 14, 4, 2], [6, 6, 20, 52, 26, 21, 27, 1, 14, 39, 46, 12, 21, 6, -23, 8, -10, 7, -13, -1, -5, -6, 4, 17, 15, -15, -17, -29, -9, -2, -4, -25, -17, -13, -3, 1, -2, 10, -17, -24, -13, -25, -15, -13, -10, -15, -15, -20, -14, -15, -21, -30, -8, -12, -15, -12, -13, -24, -13, -29, -37, -26, -23, -26, -65, -17, -22, -8, -5, -10, -1, 2, -28, -23, -11, 1, 2, -30, -25, -26, 17, 1, 10, 7, -14, -2, -10, 0, 13, 24, 5, -26, -50, 4, 13, 8, 20, 7, -7, -12, 6, 16, -1, 0, -41, -64, -7, 3, 20, 24, 2, -4, 12, -6, 1, 9, 6, -32, -27, -17, -1, 12, 21, 13, 20, 12, 0, 13, 2, -16, -15, -59, -41, 0, 9, 17, 19, 13, 9, -1, 0, -36, 3, -11, -4, -51, -44, -18, -21, -8, -15, -25, -8, -19, -70, -11, -16, -25, -70, -67, -88, -44, -80, -62, -73, -89, -42, -28, 13], [16, -22, -24, -38, -14, -35, -43, -28, -11, -35, -36, -18, 6, 7, -11, -32, -51, -60, -51, -66, -75, -70, -94, -52, -74, -1, -6, -11, 4, 2, -4, -6, -10, -8, -7, -20, -26, -55, -26, 14, 15, 12, 19, 18, 13, 2, 5, 15, 12, -1, -9, -48, 43, 21, 13, -4, 0, 3, 16, 21, 23, 14, -1, -10, -13, 47, 1, 5, -4, 0, -6, 3, 20, 13, 7, 10, -20, -34, 31, 17, 4, -3, -3, -43, -49, 2, 8, 15, 7, -16, -20, 3, 7, -3, -3, -20, -34, -15, -11, 12, 12, 25, -2, -34, -13, -7, -17, -13, -21, -9, -4, -1, 2, -10, -7, -17, -28, -32, -16, -33, -25, -27, -17, 2, -13, -22, -33, -34, -51, -39, -39, -45, -18, -9, -17, -5, -3, -15, -15, -23, -37, -67, -25, 10, -4, 14, 0, -6, -11, -5, -3, -19, -28, -12, -61, -25, 14, 33, 20, 25, 22, 21, 20, 21, 19, 15, 4, -26, -19], [22, 13, 4, -26, -66, -67, -119, -119, -74, -66, -42, -12, -19, 3, -16, -38, -9, 1, -8, 4, 7, -8, -12, -10, -25, 9, -2, -59, -22, -2, -9, -8, -2, 12, 14, 0, -7, -15, 0, -5, -5, -11, -3, 1, -2, -6, 3, 4, 9, 5, 18, 7, -34, -4, 8, 3, 10, 6, 0, -21, -3, 5, 1, 8, 6, -17, -10, 12, 11, 6, 7, 17, -7, -7, 2, 5, 14, 12, -50, -25, -7, -6, -5, 2, 4, 4, -2, 8, -2, 2, 4, -30, -37, -20, -16, -18, 14, 17, -2, -14, -15, -16, -26, -19, -36, -46, -19, -4, 8, 19, 2, -3, -8, -20, -14, -3, -57, -48, -23, -4, 1, 5, -5, -14, -11, -6, -11, 3, 6, -98, -22, -21, 7, 6, -1, -1, 1, 0, 1, -2, 2, -22, -38, -29, -21, -20, 2, -2, 3, 11, 6, 3, 8, 5, 0, -31, 6, -38, -26, -10, -9, -7, -6, 1, 5, 2, -33, -8, 2], [-18, 15, -17, -14, -28, -33, -67, -37, -57, -53, -54, -8, -25, 11, -24, -32, -41, -93, -40, -45, -66, -67, -83, -127, -63, -32, -9, -61, -75, -30, -9, -4, 6, 8, 10, -1, -15, -63, -62, -52, -71, -26, -17, -7, 0, 16, 23, 11, 2, -9, -36, -54, -73, -31, 1, -9, -4, -1, 6, -6, -2, -5, -15, -21, -38, -40, -21, 18, 13, 12, 5, 2, 7, 7, 11, 12, -5, -37, -46, 15, 13, 10, 11, -14, 2, 17, 11, 19, 11, -24, -36, -18, 9, 0, 8, -1, 5, 2, -4, 5, -5, -5, -38, -67, -40, -21, -9, -2, 0, -4, -8, 7, -4, -18, -23, -43, -45, -29, -44, -10, -16, -18, -33, -15, -7, -15, -18, -25, -12, -11, -47, -19, -12, -12, -17, -12, -8, -10, -12, -16, -11, -10, -19, -18, -32, -25, -1, -12, -14, -13, -13, -16, -3, 16, 0, 8, -17, -10, 29, 29, 11, 7, 9, 14, 17, 18, 19, 9, 13]])

fc_bias = np.array([-1731, 2275, 310, -865, -45, 3101, -612, 1869, -3584, -711])
fc_q_param = np.array([-467, -568, -157, -235, -475, -208, -388, -411, -383, -646])


#plt.imshow(test_data_instance)
#plt.show()

#f = open("E:\\MTP\\laconic_on_simple_network\\deviation.txt", "w")
#f.write("index, original, approx\n")

cases_diff2 = 0
total_cases = 0

def conv_1st_layer():

    global cases_diff2
    global total_cases
    
    cov_res = np.zeros((26, 26))
    acc_mac_only = 0
    laconic_acc = 0

    for i in range(26):
        #print(i, "--------")
        for j in range(26):
            
            activation_slice = test_data_instance[i:i+3, j:j+3].astype(np.int8)

            #use software---------------------------------------------------
            acc_mac_only = np.sum(np.multiply(activation_slice, w1_conv))
            #---------------------------------------------------------------

            #use laconic----------------------------------------------------
            input_A_W(activation_slice, w1_conv)
            laconic_acc_1 = laconic_simulator_result()
            #---------------------------------------------------------------
			
            cov_res[i][j] = -128 + 0.0078535 * (laconic_acc_1 + 1702)
			
			
            #print("Exact : ", cov_res[i][j])
            #print("Exact : ", cov_res[i][j])

            
         

            total_cases += 1
            if(laconic_acc_1 != acc_mac_only):
                
                #dev = "\n" + str(cases_diff2) + ", " + str(acc_mac_only) + ", " + str(laconic_acc_1)
                cases_diff2 += 1
                #f.write(dev)
                
                #print("-----")
                #print("laconic_acc_1 ", laconic_acc2)
                #print("acc_mac_only ", acc_mac_only)
            
            
    #print(cov_res)
    cov_res_relu = np.maximum(-128, np.round(cov_res))
    cov_res_relu = np.minimum(127, cov_res_relu)
    #print(cov_res_relu)

    #cov_res_relu = cov_res_relu.astype(np.int)
    
    maxpool_res = skimage.measure.block_reduce(cov_res_relu, (2,2), np.max)
    maxpool_res = maxpool_res.astype(np.int8)
    #print(maxpool_res)
    
    flat_res = maxpool_res.flatten()
    #print(flat_res)

    acc_mac_only2 = 0
    final_res = np.zeros(10)

    for i in range(10):
       
        #use_software------------------------------------------------------
        acc_mac_only2 = np.sum(np.multiply(w_fc[i], flat_res))
        #------------------------------------------------------------------
        #print("software 2 : ", acc_mac_only2)

        #use_laconic-------------------------------------------------------
        input_A_W(w_fc[i], flat_res)
        laconic_acc2 = laconic_simulator_result()
        #------------------------------------------------------------------
        #print("laconic 2 : ", acc_mac_only2_l)

        #print(acc_mac_only2)
        #final_res[i] = (0.002144*(acc_mac_only2 + fc_bias[i])) + (128*0.002144*np.sum(w_fc[i])) + 68
        final_res[i] = (0.002144*(laconic_acc2 + fc_bias[i])) + fc_q_param[i]

        #print("Exact", final_res[i])

        
        #print(final_res[i])

        total_cases += 1
        if(laconic_acc2 != acc_mac_only2):
            
            #dev = "\n" + str(cases_diff2) + ", " + str(acc_mac_only2) + ", " + str(laconic_acc2)
            cases_diff2 += 1
            #f.write(dev)
            #print("-----")

            #print("acc_mac_only2 ", acc_mac_only2)
            #print("laconic_acc2 ", laconic_acc2)

            #print("flat_res2 ", flat_res2)
            #print("w_fc[i] ", w_fc[i])

        

    #print("qparam :", q_param)

    final_res = np.maximum(-128, np.round(final_res))
    final_res = np.minimum(127, final_res)


    #print(final_res)
    #print(test_label_instance)
    #print(np.max(final_res))
    #print(final_res.argmax())
    
    return final_res.argmax()


##--- test cases ---
test_range = 10
##------------------

correct_predict = 0





print("Model eval started...")

for i in range(test_range):
    test_data_instance = test_images[i]
    test_label_instance = test_labels[i]
    
    predicted_op = conv_1st_layer()
    
    if (test_label_instance==predicted_op):
        correct_predict += 1
    
    #print("Actual:", test_labels[i], "  --  Predicted:", predicted_op)
    
print("Accuracy :", correct_predict / test_range * 100, "%")
#print("bin :", bin)
print("Mismatch cases : ", cases_diff2)
print("total_cases : ", total_cases)

#f.close()
